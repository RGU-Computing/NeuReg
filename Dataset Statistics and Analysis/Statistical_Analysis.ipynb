{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70db06d0-5d95-4745-b24e-0869e0c8ed54",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#  QA Dataset Analysis - Readability, Length Distribution & Vocabulary Diversity\n",
    "\n",
    "\n",
    "\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Jupyter-specific settings\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['font.size'] = 10\n",
    "\n",
    "import textstat\n",
    "print(\"All libraries imported successfully!\")\n",
    "\n",
    "\n",
    "class FocusedQAAnalyzer:\n",
    "    \"\"\"analysis for readability, length distribution, and vocabulary diversity.\"\"\"\n",
    "    \n",
    "    def __init__(self, json_file_paths):\n",
    "        \"\"\"Initialize with paths to the JSON dataset files.\"\"\"\n",
    "        self.json_files = json_file_paths\n",
    "        self.df = self._load_all_datasets()\n",
    "        self.shot_types = self.df['shot_type'].unique()\n",
    "        self.question_types = self.df['question_type'].unique()\n",
    "        \n",
    "        print(f\" Loaded datasets with {len(self.df)} QA pairs\")\n",
    "        print(f\" Shot types: {list(self.shot_types)}\")\n",
    "        print(f\" Question types: {list(self.question_types)}\")\n",
    "        \n",
    "        # Calculate lengths\n",
    "        self.df['question_length'] = self.df['question'].fillna('').astype(str).apply(lambda x: len(x.split()))\n",
    "        self.df['answer_length'] = self.df['answer'].fillna('').astype(str).apply(lambda x: len(x.split()))\n",
    "        \n",
    "        # Display distribution\n",
    "        print(f\"\\n Dataset Distribution:\")\n",
    "        distribution = self.df.groupby(['shot_type', 'question_type']).size().unstack(fill_value=0)\n",
    "        print(distribution)\n",
    "    \n",
    "    def _load_all_datasets(self):\n",
    "        \"\"\"Load and combine all JSON datasets.\"\"\"\n",
    "        all_data = []\n",
    "        \n",
    "        for shot_type, file_path in self.json_files.items():\n",
    "            print(f\" Loading {shot_type} dataset from: {file_path}\")\n",
    "            \n",
    "            try:\n",
    "                with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "                    data = json.load(f)\n",
    "            except FileNotFoundError:\n",
    "                print(f\" File not found: {file_path}\")\n",
    "                continue\n",
    "            except json.JSONDecodeError:\n",
    "                print(f\" Invalid JSON in file: {file_path}\")\n",
    "                continue\n",
    "            \n",
    "            queries = data.get(\"queries\", [])\n",
    "            print(f\" Found {len(queries)} QA pairs\")\n",
    "            \n",
    "            for item in queries:\n",
    "                qtype = item.get(\"question_type\", \"\").lower().strip()\n",
    "                \n",
    "                # Skip if question type is not in our target types\n",
    "                question_types = [\"factual\", \"relationship\", \"comparative\", \"inferential\"]\n",
    "                if qtype not in question_types:\n",
    "                    continue\n",
    "                \n",
    "                all_data.append({\n",
    "                    \"qa_id\": item.get(\"id\", \"\"),\n",
    "                    \"question_type\": qtype,\n",
    "                    \"shot_type\": shot_type,\n",
    "                    \"question\": item.get(\"question\", \"\"),\n",
    "                    \"answer\": item.get(\"answer\", \"\")\n",
    "                })\n",
    "        \n",
    "        df = pd.DataFrame(all_data)\n",
    "        print(f\"\\n Combined dataset: {len(df)} total QA pairs\")\n",
    "        return df\n",
    "    \n",
    "    def type_token_ratio(self, text):\n",
    "        \"\"\"Calculate Type-Token Ratio for vocabulary diversity.\"\"\"\n",
    "        if not text or pd.isna(text):\n",
    "            return 0\n",
    "        tokens = str(text).lower().split()\n",
    "        if len(tokens) == 0:\n",
    "            return 0\n",
    "        types = set(tokens)\n",
    "        return len(types) / len(tokens)\n",
    "    \n",
    "    def readability_scores(self, text):\n",
    "        \"\"\"Calculate readability metrics using textstat.\"\"\"\n",
    "        if not text or pd.isna(text):\n",
    "            return {\"Flesch-Kincaid\": 0, \"Gunning Fog\": 0}\n",
    "        \n",
    "        text = str(text)\n",
    "        try:\n",
    "            fk = textstat.flesch_kincaid_grade(text)\n",
    "            gf = textstat.gunning_fog(text)\n",
    "            return {\"Flesch-Kincaid\": round(fk, 2), \"Gunning Fog\": round(gf, 2)}\n",
    "        except:\n",
    "            return {\"Flesch-Kincaid\": 0, \"Gunning Fog\": 0}\n",
    "\n",
    "json_file_paths = {\n",
    "    \"zero_shot\": \"Zero-Shot_qa_dataset.json\",\n",
    "    \"one_shot\": \"One-Shot_qa_dataset.json\", \n",
    "    \"few_shot\": \"Few-Shot_qa_dataset.json\"\n",
    "}\n",
    "\n",
    "try:\n",
    "    analyzer = FocusedQAAnalyzer(json_file_paths)\n",
    "except Exception as e:\n",
    "    print(f\" Error loading datasets: {e}\")\n",
    "    print(\"Please update the json_file_paths with correct paths to your JSON files.\")\n",
    "\n",
    "def analyze_readability(analyzer):\n",
    "    \"\"\"Analyze readability (Flesch-Kincaid and Gunning Fog) by shot types, question types, questions, and answers.\"\"\"\n",
    "    print(\" READABILITY ANALYSIS\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    # Overall readability\n",
    "    all_questions = \" \".join(analyzer.df['question'].fillna('').astype(str))\n",
    "    all_answers = \" \".join(analyzer.df['answer'].fillna('').astype(str))\n",
    "    \n",
    "    overall_readability_q = analyzer.readability_scores(all_questions)\n",
    "    overall_readability_a = analyzer.readability_scores(all_answers)\n",
    "    \n",
    "    results['overall'] = {\n",
    "        'questions': overall_readability_q,\n",
    "        'answers': overall_readability_a\n",
    "    }\n",
    "    \n",
    "    print(f\" Overall Readability:\")\n",
    "    print(f\"   Questions: FK={overall_readability_q['Flesch-Kincaid']}, GF={overall_readability_q['Gunning Fog']}\")\n",
    "    print(f\"   Answers: FK={overall_readability_a['Flesch-Kincaid']}, GF={overall_readability_a['Gunning Fog']}\")\n",
    "    \n",
    "    # Create comprehensive readability table\n",
    "    readability_data = []\n",
    "    \n",
    "    # Overall data\n",
    "    readability_data.append({\n",
    "        'Category': 'Overall',\n",
    "        'Type': 'Questions',\n",
    "        'Sample Count': f\"{len(analyzer.df):,}\",\n",
    "        'Flesch-Kincaid': overall_readability_q['Flesch-Kincaid'],\n",
    "        'Gunning Fog': overall_readability_q['Gunning Fog']\n",
    "    })\n",
    "    readability_data.append({\n",
    "        'Category': 'Overall',\n",
    "        'Type': 'Answers',\n",
    "        'Sample Count': f\"{len(analyzer.df):,}\",\n",
    "        'Flesch-Kincaid': overall_readability_a['Flesch-Kincaid'],\n",
    "        'Gunning Fog': overall_readability_a['Gunning Fog']\n",
    "    })\n",
    "    \n",
    "    # Readability by shot type\n",
    "    print(f\"\\n Readability by Shot Type:\")\n",
    "    results['by_shot_type'] = {}\n",
    "    \n",
    "    for shot_type in analyzer.shot_types:\n",
    "        subset = analyzer.df[analyzer.df['shot_type'] == shot_type]\n",
    "        questions_text = \" \".join(subset['question'].fillna('').astype(str))\n",
    "        answers_text = \" \".join(subset['answer'].fillna('').astype(str))\n",
    "        \n",
    "        readability_q = analyzer.readability_scores(questions_text)\n",
    "        readability_a = analyzer.readability_scores(answers_text)\n",
    "        \n",
    "        results['by_shot_type'][shot_type] = {\n",
    "            'questions': readability_q,\n",
    "            'answers': readability_a\n",
    "        }\n",
    "        \n",
    "        readability_data.append({\n",
    "            'Category': shot_type,\n",
    "            'Type': 'Questions',\n",
    "            'Sample Count': f\"{len(subset):,}\",\n",
    "            'Flesch-Kincaid': readability_q['Flesch-Kincaid'],\n",
    "            'Gunning Fog': readability_q['Gunning Fog']\n",
    "        })\n",
    "        readability_data.append({\n",
    "            'Category': shot_type,\n",
    "            'Type': 'Answers',\n",
    "            'Sample Count': f\"{len(subset):,}\",\n",
    "            'Flesch-Kincaid': readability_a['Flesch-Kincaid'],\n",
    "            'Gunning Fog': readability_a['Gunning Fog']\n",
    "        })\n",
    "        \n",
    "        print(f\"   {shot_type} (n={len(subset):,}):\")\n",
    "        print(f\"     Questions: FK={readability_q['Flesch-Kincaid']}, GF={readability_q['Gunning Fog']}\")\n",
    "        print(f\"     Answers: FK={readability_a['Flesch-Kincaid']}, GF={readability_a['Gunning Fog']}\")\n",
    "    \n",
    "    # Readability by question type\n",
    "    print(f\"\\n Readability by Question Type:\")\n",
    "    results['by_question_type'] = {}\n",
    "    \n",
    "    for q_type in analyzer.question_types:\n",
    "        subset = analyzer.df[analyzer.df['question_type'] == q_type]\n",
    "        questions_text = \" \".join(subset['question'].fillna('').astype(str))\n",
    "        answers_text = \" \".join(subset['answer'].fillna('').astype(str))\n",
    "        \n",
    "        readability_q = analyzer.readability_scores(questions_text)\n",
    "        readability_a = analyzer.readability_scores(answers_text)\n",
    "        \n",
    "        results['by_question_type'][q_type] = {\n",
    "            'questions': readability_q,\n",
    "            'answers': readability_a\n",
    "        }\n",
    "        \n",
    "        readability_data.append({\n",
    "            'Category': q_type,\n",
    "            'Type': 'Questions',\n",
    "            'Sample Count': f\"{len(subset):,}\",\n",
    "            'Flesch-Kincaid': readability_q['Flesch-Kincaid'],\n",
    "            'Gunning Fog': readability_q['Gunning Fog']\n",
    "        })\n",
    "        readability_data.append({\n",
    "            'Category': q_type,\n",
    "            'Type': 'Answers',\n",
    "            'Sample Count': f\"{len(subset):,}\",\n",
    "            'Flesch-Kincaid': readability_a['Flesch-Kincaid'],\n",
    "            'Gunning Fog': readability_a['Gunning Fog']\n",
    "        })\n",
    "        \n",
    "        print(f\"   {q_type} (n={len(subset):,}):\")\n",
    "        print(f\"     Questions: FK={readability_q['Flesch-Kincaid']}, GF={readability_q['Gunning Fog']}\")\n",
    "        print(f\"     Answers: FK={readability_a['Flesch-Kincaid']}, GF={readability_a['Gunning Fog']}\")\n",
    "    \n",
    "    # Display comprehensive readability table\n",
    "    readability_df = pd.DataFrame(readability_data)\n",
    "    print(f\"\\n Comprehensive Readability Summary:\")\n",
    "    print(readability_df.to_string(index=False))\n",
    "    \n",
    "    return results, readability_df\n",
    "\n",
    "#  Answer Length Distribution Analysis\n",
    "def analyze_answer_length_distribution(analyzer):\n",
    "    \"\"\"Analyze answer length distribution by shot types and question types using categorical classifications.\"\"\"\n",
    "    print(\"\\n ANSWER LENGTH DISTRIBUTION ANALYSIS\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    def categorize_length(length):\n",
    "        \"\"\"Categorize answer length: short (<30), medium (30-60), long (>60).\"\"\"\n",
    "        if length < 30:\n",
    "            return \"Short\"\n",
    "        elif 30 <= length <= 60:\n",
    "            return \"Medium\"\n",
    "        else:\n",
    "            return \"Long\"\n",
    "    \n",
    "    # Add length categories to dataframe\n",
    "    analyzer.df['length_category'] = analyzer.df['answer_length'].apply(categorize_length)\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    # Overall length distribution\n",
    "    overall_dist = analyzer.df['length_category'].value_counts()\n",
    "    overall_total = len(analyzer.df)\n",
    "    results['overall'] = {\n",
    "        'short': overall_dist.get('Short', 0),\n",
    "        'medium': overall_dist.get('Medium', 0),\n",
    "        'long': overall_dist.get('Long', 0),\n",
    "        'total': overall_total\n",
    "    }\n",
    "    \n",
    "    print(f\" Overall Answer Length Distribution:\")\n",
    "    print(f\"   Short (<30 words): {overall_dist.get('Short', 0):,} ({overall_dist.get('Short', 0)/overall_total*100:.1f}%)\")\n",
    "    print(f\"   Medium (30-60 words): {overall_dist.get('Medium', 0):,} ({overall_dist.get('Medium', 0)/overall_total*100:.1f}%)\")\n",
    "    print(f\"   Long (>60 words): {overall_dist.get('Long', 0):,} ({overall_dist.get('Long', 0)/overall_total*100:.1f}%)\")\n",
    "    \n",
    "    # Create comprehensive length analysis table\n",
    "    length_data = []\n",
    "    \n",
    "    # Overall data\n",
    "    length_data.append({\n",
    "        'Category': 'Overall',\n",
    "        'Type': 'All',\n",
    "        'Sample Count': f\"{overall_total:,}\",\n",
    "        'Short (<30)': f\"{overall_dist.get('Short', 0):,} ({overall_dist.get('Short', 0)/overall_total*100:.1f}%)\",\n",
    "        'Medium (30-60)': f\"{overall_dist.get('Medium', 0):,} ({overall_dist.get('Medium', 0)/overall_total*100:.1f}%)\",\n",
    "        'Long (>60)': f\"{overall_dist.get('Long', 0):,} ({overall_dist.get('Long', 0)/overall_total*100:.1f}%)\"\n",
    "    })\n",
    "    \n",
    "    # By shot type\n",
    "    print(f\"\\n Answer Length Distribution by Shot Type:\")\n",
    "    results['by_shot_type'] = {}\n",
    "    \n",
    "    for shot_type in analyzer.shot_types:\n",
    "        subset = analyzer.df[analyzer.df['shot_type'] == shot_type]\n",
    "        dist = subset['length_category'].value_counts()\n",
    "        total = len(subset)\n",
    "        \n",
    "        results['by_shot_type'][shot_type] = {\n",
    "            'short': dist.get('Short', 0),\n",
    "            'medium': dist.get('Medium', 0),\n",
    "            'long': dist.get('Long', 0),\n",
    "            'total': total\n",
    "        }\n",
    "        \n",
    "        length_data.append({\n",
    "            'Category': shot_type,\n",
    "            'Type': 'Shot Type',\n",
    "            'Sample Count': f\"{total:,}\",\n",
    "            'Short (<30)': f\"{dist.get('Short', 0):,} ({dist.get('Short', 0)/total*100:.1f}%)\",\n",
    "            'Medium (30-60)': f\"{dist.get('Medium', 0):,} ({dist.get('Medium', 0)/total*100:.1f}%)\",\n",
    "            'Long (>60)': f\"{dist.get('Long', 0):,} ({dist.get('Long', 0)/total*100:.1f}%)\"\n",
    "        })\n",
    "        \n",
    "        print(f\"   {shot_type} (n={total:,}):\")\n",
    "        print(f\"     Short: {dist.get('Short', 0):,} ({dist.get('Short', 0)/total*100:.1f}%)\")\n",
    "        print(f\"     Medium: {dist.get('Medium', 0):,} ({dist.get('Medium', 0)/total*100:.1f}%)\")\n",
    "        print(f\"     Long: {dist.get('Long', 0):,} ({dist.get('Long', 0)/total*100:.1f}%)\")\n",
    "    \n",
    "    # By question type\n",
    "    print(f\"\\n Answer Length Distribution by Question Type:\")\n",
    "    results['by_question_type'] = {}\n",
    "    \n",
    "    for q_type in analyzer.question_types:\n",
    "        subset = analyzer.df[analyzer.df['question_type'] == q_type]\n",
    "        dist = subset['length_category'].value_counts()\n",
    "        total = len(subset)\n",
    "        \n",
    "        results['by_question_type'][q_type] = {\n",
    "            'short': dist.get('Short', 0),\n",
    "            'medium': dist.get('Medium', 0),\n",
    "            'long': dist.get('Long', 0),\n",
    "            'total': total\n",
    "        }\n",
    "        \n",
    "        length_data.append({\n",
    "            'Category': q_type,\n",
    "            'Type': 'Question Type',\n",
    "            'Sample Count': f\"{total:,}\",\n",
    "            'Short (<30)': f\"{dist.get('Short', 0):,} ({dist.get('Short', 0)/total*100:.1f}%)\",\n",
    "            'Medium (30-60)': f\"{dist.get('Medium', 0):,} ({dist.get('Medium', 0)/total*100:.1f}%)\",\n",
    "            'Long (>60)': f\"{dist.get('Long', 0):,} ({dist.get('Long', 0)/total*100:.1f}%)\"\n",
    "        })\n",
    "        \n",
    "        print(f\"   {q_type} (n={total:,}):\")\n",
    "        print(f\"     Short: {dist.get('Short', 0):,} ({dist.get('Short', 0)/total*100:.1f}%)\")\n",
    "        print(f\"     Medium: {dist.get('Medium', 0):,} ({dist.get('Medium', 0)/total*100:.1f}%)\")\n",
    "        print(f\"     Long: {dist.get('Long', 0):,} ({dist.get('Long', 0)/total*100:.1f}%)\")\n",
    "    \n",
    "    # Display comprehensive length table\n",
    "    length_df = pd.DataFrame(length_data)\n",
    "    print(f\"\\n Comprehensive Answer Length Summary:\")\n",
    "    print(length_df.to_string(index=False))\n",
    "    \n",
    "    return results, length_df\n",
    "\n",
    "#  Vocabulary Diversity Analysis\n",
    "def analyze_vocabulary_diversity(analyzer):\n",
    "    \"\"\"Analyze vocabulary diversity by shot types and question types.\"\"\"\n",
    "    print(\"\\n VOCABULARY DIVERSITY ANALYSIS\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    # Overall diversity\n",
    "    all_questions = \" \".join(analyzer.df['question'].fillna('').astype(str))\n",
    "    all_answers = \" \".join(analyzer.df['answer'].fillna('').astype(str))\n",
    "    \n",
    "    overall_ttr_q = analyzer.type_token_ratio(all_questions)\n",
    "    overall_ttr_a = analyzer.type_token_ratio(all_answers)\n",
    "    \n",
    "    results['overall'] = {\n",
    "        'questions_ttr': round(overall_ttr_q, 4),\n",
    "        'answers_ttr': round(overall_ttr_a, 4)\n",
    "    }\n",
    "    \n",
    "    print(f\" Overall Vocabulary Diversity:\")\n",
    "    print(f\"   Questions TTR: {overall_ttr_q:.4f}\")\n",
    "    print(f\"   Answers TTR: {overall_ttr_a:.4f}\")\n",
    "    \n",
    "    # Create comprehensive diversity table\n",
    "    diversity_data = []\n",
    "    \n",
    "    # Overall data\n",
    "    diversity_data.append({\n",
    "        'Category': 'Overall',\n",
    "        'Type': 'Questions',\n",
    "        'Sample Count': f\"{len(analyzer.df):,}\",\n",
    "        'TTR': round(overall_ttr_q, 4),\n",
    "        'Vocab Size': len(set(all_questions.lower().split()))\n",
    "    })\n",
    "    diversity_data.append({\n",
    "        'Category': 'Overall',\n",
    "        'Type': 'Answers',\n",
    "        'Sample Count': f\"{len(analyzer.df):,}\",\n",
    "        'TTR': round(overall_ttr_a, 4),\n",
    "        'Vocab Size': len(set(all_answers.lower().split()))\n",
    "    })\n",
    "    \n",
    "    # Diversity by shot type\n",
    "    print(f\"\\n Diversity by Shot Type:\")\n",
    "    results['by_shot_type'] = {}\n",
    "    \n",
    "    for shot_type in analyzer.shot_types:\n",
    "        subset = analyzer.df[analyzer.df['shot_type'] == shot_type]\n",
    "        questions_text = \" \".join(subset['question'].fillna('').astype(str))\n",
    "        answers_text = \" \".join(subset['answer'].fillna('').astype(str))\n",
    "        \n",
    "        ttr_q = analyzer.type_token_ratio(questions_text)\n",
    "        ttr_a = analyzer.type_token_ratio(answers_text)\n",
    "        \n",
    "        results['by_shot_type'][shot_type] = {\n",
    "            'questions_ttr': round(ttr_q, 4),\n",
    "            'answers_ttr': round(ttr_a, 4),\n",
    "            'sample_count': len(subset)\n",
    "        }\n",
    "        \n",
    "        diversity_data.append({\n",
    "            'Category': shot_type,\n",
    "            'Type': 'Questions',\n",
    "            'Sample Count': f\"{len(subset):,}\",\n",
    "            'TTR': round(ttr_q, 4),\n",
    "            'Vocab Size': len(set(questions_text.lower().split()))\n",
    "        })\n",
    "        diversity_data.append({\n",
    "            'Category': shot_type,\n",
    "            'Type': 'Answers',\n",
    "            'Sample Count': f\"{len(subset):,}\",\n",
    "            'TTR': round(ttr_a, 4),\n",
    "            'Vocab Size': len(set(answers_text.lower().split()))\n",
    "        })\n",
    "        \n",
    "        print(f\"   {shot_type} (n={len(subset):,}): Q_TTR={ttr_q:.4f}, A_TTR={ttr_a:.4f}\")\n",
    "    \n",
    "    # Diversity by question type\n",
    "    print(f\"\\n❓ Diversity by Question Type:\")\n",
    "    results['by_question_type'] = {}\n",
    "    \n",
    "    for q_type in analyzer.question_types:\n",
    "        subset = analyzer.df[analyzer.df['question_type'] == q_type]\n",
    "        questions_text = \" \".join(subset['question'].fillna('').astype(str))\n",
    "        answers_text = \" \".join(subset['answer'].fillna('').astype(str))\n",
    "        \n",
    "        ttr_q = analyzer.type_token_ratio(questions_text)\n",
    "        ttr_a = analyzer.type_token_ratio(answers_text)\n",
    "        \n",
    "        results['by_question_type'][q_type] = {\n",
    "            'questions_ttr': round(ttr_q, 4),\n",
    "            'answers_ttr': round(ttr_a, 4),\n",
    "            'sample_count': len(subset)\n",
    "        }\n",
    "        \n",
    "        diversity_data.append({\n",
    "            'Category': q_type,\n",
    "            'Type': 'Questions',\n",
    "            'Sample Count': f\"{len(subset):,}\",\n",
    "            'TTR': round(ttr_q, 4),\n",
    "            'Vocab Size': len(set(questions_text.lower().split()))\n",
    "        })\n",
    "        diversity_data.append({\n",
    "            'Category': q_type,\n",
    "            'Type': 'Answers',\n",
    "            'Sample Count': f\"{len(subset):,}\",\n",
    "            'TTR': round(ttr_a, 4),\n",
    "            'Vocab Size': len(set(answers_text.lower().split()))\n",
    "        })\n",
    "        \n",
    "        print(f\"   {q_type} (n={len(subset):,}): Q_TTR={ttr_q:.4f}, A_TTR={ttr_a:.4f}\")\n",
    "    \n",
    "    # Display comprehensive diversity table\n",
    "    diversity_df = pd.DataFrame(diversity_data)\n",
    "    print(f\"\\n Comprehensive Vocabulary Diversity Summary:\")\n",
    "    print(diversity_df.to_string(index=False))\n",
    "    \n",
    "    return results, diversity_df\n",
    "\n",
    "# Complete Comprehensive Visualization\n",
    "def create_comprehensive_visualization(analyzer, readability_results, length_results, diversity_results):\n",
    "    \"\"\"Create one complete graph with all analyses.\"\"\"\n",
    "    print(\" CREATING COMPREHENSIVE VISUALIZATION\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Create figure with 12 subplots (3 rows × 4 columns)\n",
    "    fig = plt.figure(figsize=(24, 18))\n",
    "    \n",
    "    # 1. Readability - Flesch-Kincaid by Shot Type\n",
    "    plt.subplot(3, 4, 1)\n",
    "    shot_types_clean = [st.replace('_', '-').title() for st in analyzer.shot_types]\n",
    "    fk_questions = [readability_results[0]['by_shot_type'][st]['questions']['Flesch-Kincaid'] for st in analyzer.shot_types]\n",
    "    fk_answers = [readability_results[0]['by_shot_type'][st]['answers']['Flesch-Kincaid'] for st in analyzer.shot_types]\n",
    "    \n",
    "    x = np.arange(len(shot_types_clean))\n",
    "    width = 0.35\n",
    "    plt.bar(x - width/2, fk_questions, width, label='Questions', alpha=0.8, color='#FF6B6B')\n",
    "    plt.bar(x + width/2, fk_answers, width, label='Answers', alpha=0.8, color='#4ECDC4')\n",
    "    plt.xlabel('Shot Type')\n",
    "    plt.ylabel('Flesch-Kincaid Grade Level')\n",
    "    plt.title('Readability (Flesch-Kincaid)\\nby Shot Type', fontweight='bold', fontsize=12)\n",
    "    plt.xticks(x, shot_types_clean)\n",
    "    plt.legend()\n",
    "    \n",
    "    # 2. Readability - Gunning Fog by Shot Type\n",
    "    plt.subplot(3, 4, 2)\n",
    "    gf_questions = [readability_results[0]['by_shot_type'][st]['questions']['Gunning Fog'] for st in analyzer.shot_types]\n",
    "    gf_answers = [readability_results[0]['by_shot_type'][st]['answers']['Gunning Fog'] for st in analyzer.shot_types]\n",
    "    \n",
    "    plt.bar(x - width/2, gf_questions, width, label='Questions', alpha=0.8, color='#FF9FF3')\n",
    "    plt.bar(x + width/2, gf_answers, width, label='Answers', alpha=0.8, color='#54A0FF')\n",
    "    plt.xlabel('Shot Type')\n",
    "    plt.ylabel('Gunning Fog Index')\n",
    "    plt.title('Readability (Gunning Fog)\\nby Shot Type', fontweight='bold', fontsize=12)\n",
    "    plt.xticks(x, shot_types_clean)\n",
    "    plt.legend()\n",
    "    \n",
    "    # 3. Readability - Flesch-Kincaid by Question Type\n",
    "    plt.subplot(3, 4, 3)\n",
    "    fk_q_by_type = [readability_results[0]['by_question_type'][qt]['questions']['Flesch-Kincaid'] for qt in analyzer.question_types]\n",
    "    fk_a_by_type = [readability_results[0]['by_question_type'][qt]['answers']['Flesch-Kincaid'] for qt in analyzer.question_types]\n",
    "    \n",
    "    x_q = np.arange(len(analyzer.question_types))\n",
    "    plt.bar(x_q - width/2, fk_q_by_type, width, label='Questions', alpha=0.8, color='#96CEB4')\n",
    "    plt.bar(x_q + width/2, fk_a_by_type, width, label='Answers', alpha=0.8, color='#FECA57')\n",
    "    plt.xlabel('Question Type')\n",
    "    plt.ylabel('Flesch-Kincaid Grade Level')\n",
    "    plt.title('Readability (Flesch-Kincaid)\\nby Question Type', fontweight='bold', fontsize=12)\n",
    "    plt.xticks(x_q, analyzer.question_types, rotation=45)\n",
    "    plt.legend()\n",
    "    \n",
    "    # 4. Readability - Gunning Fog by Question Type\n",
    "    plt.subplot(3, 4, 4)\n",
    "    gf_q_by_type = [readability_results[0]['by_question_type'][qt]['questions']['Gunning Fog'] for qt in analyzer.question_types]\n",
    "    gf_a_by_type = [readability_results[0]['by_question_type'][qt]['answers']['Gunning Fog'] for qt in analyzer.question_types]\n",
    "    \n",
    "    plt.bar(x_q - width/2, gf_q_by_type, width, label='Questions', alpha=0.8, color='#FF6B6B')\n",
    "    plt.bar(x_q + width/2, gf_a_by_type, width, label='Answers', alpha=0.8, color='#4ECDC4')\n",
    "    plt.xlabel('Question Type')\n",
    "    plt.ylabel('Gunning Fog Index')\n",
    "    plt.title('Readability (Gunning Fog)\\nby Question Type', fontweight='bold', fontsize=12)\n",
    "    plt.xticks(x_q, analyzer.question_types, rotation=45)\n",
    "    plt.legend()\n",
    "    \n",
    "    # 5. Answer Length Distribution by Shot Type\n",
    "    plt.subplot(3, 4, 5)\n",
    "    colors_shot = ['#FF6B6B', '#4ECDC4', '#45B7D1']\n",
    "    for i, shot_type in enumerate(analyzer.shot_types):\n",
    "        subset = analyzer.df[analyzer.df['shot_type'] == shot_type]\n",
    "        plt.hist(subset['answer_length'], alpha=0.6, label=shot_type, bins=30, \n",
    "                density=True, color=colors_shot[i])\n",
    "    plt.xlabel('Answer Length (words)')\n",
    "    plt.ylabel('Density')\n",
    "    plt.title('Answer Length Distribution\\nby Shot Type', fontweight='bold', fontsize=12)\n",
    "    plt.legend()\n",
    "    \n",
    "    # 6. Answer Length Distribution by Question Type\n",
    "    plt.subplot(3, 4, 6)\n",
    "    colors_q = ['#96CEB4', '#FECA57', '#FF9FF3', '#54A0FF']\n",
    "    for i, q_type in enumerate(analyzer.question_types):\n",
    "        subset = analyzer.df[analyzer.df['question_type'] == q_type]\n",
    "        plt.hist(subset['answer_length'], alpha=0.6, label=q_type, bins=25, \n",
    "                density=True, color=colors_q[i])\n",
    "    plt.xlabel('Answer Length (words)')\n",
    "    plt.ylabel('Density')\n",
    "    plt.title('Answer Length Distribution\\nby Question Type', fontweight='bold', fontsize=12)\n",
    "    plt.legend()\n",
    "    \n",
    "    # 7. Answer Length Categories by Shot Type\n",
    "    plt.subplot(3, 4, 7)\n",
    "    categories = ['Short', 'Medium', 'Long']\n",
    "    shot_type_counts = []\n",
    "    \n",
    "    for shot_type in analyzer.shot_types:\n",
    "        counts = []\n",
    "        subset = analyzer.df[analyzer.df['shot_type'] == shot_type]\n",
    "        dist = subset['length_category'].value_counts()\n",
    "        total = len(subset)\n",
    "        for cat in categories:\n",
    "            counts.append(dist.get(cat, 0) / total * 100)  # Convert to percentages\n",
    "        shot_type_counts.append(counts)\n",
    "    \n",
    "    x_pos = np.arange(len(categories))\n",
    "    width = 0.25\n",
    "    colors_shot = ['#FF6B6B', '#4ECDC4', '#45B7D1']\n",
    "    \n",
    "    for i, (shot_type, counts) in enumerate(zip(analyzer.shot_types, shot_type_counts)):\n",
    "        plt.bar(x_pos + i * width, counts, width, label=shot_type, alpha=0.8, color=colors_shot[i])\n",
    "    \n",
    "    plt.xlabel('Answer Length Category')\n",
    "    plt.ylabel('Percentage (%)')\n",
    "    plt.title('Answer Length Categories\\nby Shot Type', fontweight='bold', fontsize=12)\n",
    "    plt.xticks(x_pos + width, categories)\n",
    "    plt.legend()\n",
    "    \n",
    "    # 8. Answer Length Categories by Question Type\n",
    "    plt.subplot(3, 4, 8)\n",
    "    question_type_counts = []\n",
    "    \n",
    "    for q_type in analyzer.question_types:\n",
    "        counts = []\n",
    "        subset = analyzer.df[analyzer.df['question_type'] == q_type]\n",
    "        dist = subset['length_category'].value_counts()\n",
    "        total = len(subset)\n",
    "        for cat in categories:\n",
    "            counts.append(dist.get(cat, 0) / total * 100)  # Convert to percentages\n",
    "        question_type_counts.append(counts)\n",
    "    \n",
    "    colors_q = ['#96CEB4', '#FECA57', '#FF9FF3', '#54A0FF']\n",
    "    \n",
    "    for i, (q_type, counts) in enumerate(zip(analyzer.question_types, question_type_counts)):\n",
    "        plt.bar(x_pos + i * width * 0.7, counts, width * 0.7, label=q_type, alpha=0.8, color=colors_q[i])\n",
    "    \n",
    "    plt.xlabel('Answer Length Category')\n",
    "    plt.ylabel('Percentage (%)')\n",
    "    plt.title('Answer Length Categories\\nby Question Type', fontweight='bold', fontsize=12)\n",
    "    plt.xticks(x_pos + width, categories)\n",
    "    plt.legend()\n",
    "    \n",
    "    # 9. Vocabulary Diversity (TTR) - Questions by Shot Type\n",
    "    plt.subplot(3, 4, 9)\n",
    "    ttr_q_shot = [diversity_results[0]['by_shot_type'][st]['questions_ttr'] for st in analyzer.shot_types]\n",
    "    bars = plt.bar(shot_types_clean, ttr_q_shot, color=['#FF6B6B', '#4ECDC4', '#45B7D1'], alpha=0.8)\n",
    "    plt.ylabel('Type-Token Ratio')\n",
    "    plt.title('Question Vocabulary Diversity\\nby Shot Type', fontweight='bold', fontsize=12)\n",
    "    for bar, val in zip(bars, ttr_q_shot):\n",
    "        plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.002,\n",
    "                f'{val:.3f}', ha='center', va='bottom', fontweight='bold')\n",
    "    \n",
    "    # 10. Vocabulary Diversity (TTR) - Answers by Shot Type\n",
    "    plt.subplot(3, 4, 10)\n",
    "    ttr_a_shot = [diversity_results[0]['by_shot_type'][st]['answers_ttr'] for st in analyzer.shot_types]\n",
    "    bars = plt.bar(shot_types_clean, ttr_a_shot, color=['#96CEB4', '#FECA57', '#FF9FF3'], alpha=0.8)\n",
    "    plt.ylabel('Type-Token Ratio')\n",
    "    plt.title('Answer Vocabulary Diversity\\nby Shot Type', fontweight='bold', fontsize=12)\n",
    "    for bar, val in zip(bars, ttr_a_shot):\n",
    "        plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.002,\n",
    "                f'{val:.3f}', ha='center', va='bottom', fontweight='bold')\n",
    "    \n",
    "    # 11. Vocabulary Diversity (TTR) - Questions by Question Type\n",
    "    plt.subplot(3, 4, 11)\n",
    "    ttr_q_type = [diversity_results[0]['by_question_type'][qt]['questions_ttr'] for qt in analyzer.question_types]\n",
    "    bars = plt.bar(analyzer.question_types, ttr_q_type, color=colors_q, alpha=0.8)\n",
    "    plt.ylabel('Type-Token Ratio')\n",
    "    plt.title('Question Vocabulary Diversity\\nby Question Type', fontweight='bold', fontsize=12)\n",
    "    plt.xticks(rotation=45)\n",
    "    for bar, val in zip(bars, ttr_q_type):\n",
    "        plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.002,\n",
    "                f'{val:.3f}', ha='center', va='bottom', fontweight='bold')\n",
    "    \n",
    "    # 12. Vocabulary Diversity (TTR) - Answers by Question Type\n",
    "    plt.subplot(3, 4, 12)\n",
    "    ttr_a_type = [diversity_results[0]['by_question_type'][qt]['answers_ttr'] for qt in analyzer.question_types]\n",
    "    bars = plt.bar(analyzer.question_types, ttr_a_type, color=colors_q, alpha=0.8)\n",
    "    plt.ylabel('Type-Token Ratio')\n",
    "    plt.title('Answer Vocabulary Diversity\\nby Question Type', fontweight='bold', fontsize=12)\n",
    "    plt.xticks(rotation=45)\n",
    "    for bar, val in zip(bars, ttr_a_type):\n",
    "        plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.002,\n",
    "                f'{val:.3f}', ha='center', va='bottom', fontweight='bold')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('QA_Analysis_Complete.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    print(f\" Complete analysis visualization saved to: QA_Analysis_Complete.png\")\n",
    "\n",
    "#  Generate Complete Statistical Report\n",
    "def generate_statistical_report(analyzer, readability_results, length_results, diversity_results):\n",
    "    \"\"\"Generate a comprehensive statistical report.\"\"\"\n",
    "    print(\"\\n COMPLETE STATISTICAL REPORT\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # Dataset Overview\n",
    "    total_samples = len(analyzer.df)\n",
    "    shot_distribution = analyzer.df['shot_type'].value_counts()\n",
    "    question_distribution = analyzer.df['question_type'].value_counts()\n",
    "    \n",
    "    print(f\" DATASET OVERVIEW:\")\n",
    "    print(f\"   • Total QA pairs: {total_samples:,}\")\n",
    "    print(f\"   • Shot types: {', '.join(analyzer.shot_types)}\")\n",
    "    print(f\"   • Question types: {', '.join(analyzer.question_types)}\")\n",
    "    \n",
    "    print(f\"\\n Distribution by Shot Type:\")\n",
    "    for shot_type, count in shot_distribution.items():\n",
    "        percentage = (count / total_samples) * 100\n",
    "        print(f\"   • {shot_type}: {count:,} ({percentage:.1f}%)\")\n",
    "    \n",
    "    print(f\"\\n Distribution by Question Type:\")\n",
    "    for q_type, count in question_distribution.items():\n",
    "        percentage = (count / total_samples) * 100\n",
    "        print(f\"   • {q_type}: {count:,} ({percentage:.1f}%)\")\n",
    "    \n",
    "    # Readability Summary\n",
    "    print(f\"\\n READABILITY ANALYSIS SUMMARY:\")\n",
    "    print(f\"   Overall Readability (Flesch-Kincaid):\")\n",
    "    print(f\"     • Questions: {readability_results[0]['overall']['questions']['Flesch-Kincaid']}\")\n",
    "    print(f\"     • Answers: {readability_results[0]['overall']['answers']['Flesch-Kincaid']}\")\n",
    "    \n",
    "    print(f\"\\n   Overall Readability (Gunning Fog):\")\n",
    "    print(f\"     • Questions: {readability_results[0]['overall']['questions']['Gunning Fog']}\")\n",
    "    print(f\"     • Answers: {readability_results[0]['overall']['answers']['Gunning Fog']}\")\n",
    "    \n",
    "    # Best/worst readability by shot type\n",
    "    shot_fk_q = {st: readability_results[0]['by_shot_type'][st]['questions']['Flesch-Kincaid'] for st in analyzer.shot_types}\n",
    "    shot_fk_a = {st: readability_results[0]['by_shot_type'][st]['answers']['Flesch-Kincaid'] for st in analyzer.shot_types}\n",
    "    \n",
    "    best_fk_q = min(shot_fk_q, key=shot_fk_q.get)\n",
    "    worst_fk_q = max(shot_fk_q, key=shot_fk_q.get)\n",
    "    best_fk_a = min(shot_fk_a, key=shot_fk_a.get)\n",
    "    worst_fk_a = max(shot_fk_a, key=shot_fk_a.get)\n",
    "    \n",
    "    print(f\"\\n   Readability by Shot Type (Flesch-Kincaid - lower is easier):\")\n",
    "    print(f\"     • Most readable questions: {best_fk_q} ({shot_fk_q[best_fk_q]})\")\n",
    "    print(f\"     • Least readable questions: {worst_fk_q} ({shot_fk_q[worst_fk_q]})\")\n",
    "    print(f\"     • Most readable answers: {best_fk_a} ({shot_fk_a[best_fk_a]})\")\n",
    "    print(f\"     • Least readable answers: {worst_fk_a} ({shot_fk_a[worst_fk_a]})\")\n",
    "    \n",
    "    # Length Distribution Summary\n",
    "    print(f\"\\n ANSWER LENGTH ANALYSIS SUMMARY:\")\n",
    "    overall_length = length_results[0]['overall']\n",
    "    print(f\"   Overall Answer Length Distribution:\")\n",
    "    print(f\"     • Short (<30 words): {overall_length['short']:,} ({overall_length['short']/overall_length['total']*100:.1f}%)\")\n",
    "    print(f\"     • Medium (30-60 words): {overall_length['medium']:,} ({overall_length['medium']/overall_length['total']*100:.1f}%)\")\n",
    "    print(f\"     • Long (>60 words): {overall_length['long']:,} ({overall_length['long']/overall_length['total']*100:.1f}%)\")\n",
    "    \n",
    "    # Length comparison by categories\n",
    "    shot_long_counts = {st: length_results[0]['by_shot_type'][st]['long'] for st in analyzer.shot_types}\n",
    "    shot_long_pcts = {st: length_results[0]['by_shot_type'][st]['long']/length_results[0]['by_shot_type'][st]['total']*100 for st in analyzer.shot_types}\n",
    "    q_type_long_counts = {qt: length_results[0]['by_question_type'][qt]['long'] for qt in analyzer.question_types}\n",
    "    q_type_long_pcts = {qt: length_results[0]['by_question_type'][qt]['long']/length_results[0]['by_question_type'][qt]['total']*100 for qt in analyzer.question_types}\n",
    "    \n",
    "    highest_long_shot = max(shot_long_pcts, key=shot_long_pcts.get)\n",
    "    lowest_long_shot = min(shot_long_pcts, key=shot_long_pcts.get)\n",
    "    highest_long_qtype = max(q_type_long_pcts, key=q_type_long_pcts.get)\n",
    "    lowest_long_qtype = min(q_type_long_pcts, key=q_type_long_pcts.get)\n",
    "    \n",
    "    print(f\"\\n   Length Category Comparison:\")\n",
    "    print(f\"     • Highest % long answers by shot type: {highest_long_shot} ({shot_long_pcts[highest_long_shot]:.1f}%)\")\n",
    "    print(f\"     • Lowest % long answers by shot type: {lowest_long_shot} ({shot_long_pcts[lowest_long_shot]:.1f}%)\")\n",
    "    print(f\"     • Highest % long answers by question type: {highest_long_qtype} ({q_type_long_pcts[highest_long_qtype]:.1f}%)\")\n",
    "    print(f\"     • Lowest % long answers by question type: {lowest_long_qtype} ({q_type_long_pcts[lowest_long_qtype]:.1f}%)\")\n",
    "    \n",
    "    # Vocabulary Diversity Summary\n",
    "    print(f\"\\n VOCABULARY DIVERSITY ANALYSIS SUMMARY:\")\n",
    "    overall_diversity = diversity_results[0]['overall']\n",
    "    print(f\"   Overall Vocabulary Diversity (TTR):\")\n",
    "    print(f\"     • Questions: {overall_diversity['questions_ttr']:.4f}\")\n",
    "    print(f\"     • Answers: {overall_diversity['answers_ttr']:.4f}\")\n",
    "    \n",
    "    # Best/worst diversity by categories\n",
    "    shot_div_q = {st: diversity_results[0]['by_shot_type'][st]['questions_ttr'] for st in analyzer.shot_types}\n",
    "    shot_div_a = {st: diversity_results[0]['by_shot_type'][st]['answers_ttr'] for st in analyzer.shot_types}\n",
    "    q_type_div_q = {qt: diversity_results[0]['by_question_type'][qt]['questions_ttr'] for qt in analyzer.question_types}\n",
    "    q_type_div_a = {qt: diversity_results[0]['by_question_type'][qt]['answers_ttr'] for qt in analyzer.question_types}\n",
    "    \n",
    "    best_div_shot_q = max(shot_div_q, key=shot_div_q.get)\n",
    "    best_div_shot_a = max(shot_div_a, key=shot_div_a.get)\n",
    "    best_div_qtype_q = max(q_type_div_q, key=q_type_div_q.get)\n",
    "    best_div_qtype_a = max(q_type_div_a, key=q_type_div_a.get)\n",
    "    \n",
    "    print(f\"\\n   Highest Vocabulary Diversity:\")\n",
    "    print(f\"     • Questions by shot type: {best_div_shot_q} ({shot_div_q[best_div_shot_q]:.4f})\")\n",
    "    print(f\"     • Answers by shot type: {best_div_shot_a} ({shot_div_a[best_div_shot_a]:.4f})\")\n",
    "    print(f\"     • Questions by question type: {best_div_qtype_q} ({q_type_div_q[best_div_qtype_q]:.4f})\")\n",
    "    print(f\"     • Answers by question type: {best_div_qtype_a} ({q_type_div_a[best_div_qtype_a]:.4f})\")\n",
    "    \n",
    "    # Key Insights\n",
    "    print(f\"\\n KEY INSIGHTS:\")\n",
    "    print(f\"   1. Shot Type Analysis:\")\n",
    "    print(f\"      • Most readable: {best_fk_q} (questions), {best_fk_a} (answers)\")\n",
    "    print(f\"      • Highest % long answers: {highest_long_shot}\")\n",
    "    print(f\"      • Highest vocabulary diversity: {best_div_shot_q} (questions), {best_div_shot_a} (answers)\")\n",
    "    \n",
    "    print(f\"\\n   2. Question Type Analysis:\")\n",
    "    print(f\"      • Highest % long answers: {highest_long_qtype}\")\n",
    "    print(f\"      • Lowest % long answers: {lowest_long_qtype}\")\n",
    "    print(f\"      • Highest vocabulary diversity: {best_div_qtype_q} (questions), {best_div_qtype_a} (answers)\")\n",
    "    \n",
    "    print(f\"\\n   3. Overall Patterns:\")\n",
    "    long_percentage = overall_length['long'] / overall_length['total'] * 100\n",
    "    short_percentage = overall_length['short'] / overall_length['total'] * 100\n",
    "    print(f\"      • Answer length distribution: {long_percentage:.1f}% long, {short_percentage:.1f}% short\")\n",
    "    print(f\"      • Vocabulary diversity: {'High' if overall_diversity['answers_ttr'] > 0.15 else 'Moderate'} (TTR={overall_diversity['answers_ttr']:.4f})\")\n",
    "    print(f\"      • Readability level: College-level complexity\")\n",
    "    \n",
    "    return {\n",
    "        'dataset_overview': {\n",
    "            'total_samples': total_samples,\n",
    "            'shot_distribution': dict(shot_distribution),\n",
    "            'question_distribution': dict(question_distribution)\n",
    "        },\n",
    "        'key_insights': {\n",
    "            'most_readable_shot_questions': best_fk_q,\n",
    "            'most_readable_shot_answers': best_fk_a,\n",
    "            'highest_long_answers_shot': highest_long_shot,\n",
    "            'highest_long_answers_qtype': highest_long_qtype,\n",
    "            'highest_diversity_shot_q': best_div_shot_q,\n",
    "            'highest_diversity_shot_a': best_div_shot_a,\n",
    "            'highest_diversity_qtype_q': best_div_qtype_q,\n",
    "            'highest_diversity_qtype_a': best_div_qtype_a\n",
    "        }\n",
    "    }\n",
    "\n",
    "def save_focused_results(analyzer, readability_results, length_results, diversity_results, report_summary):\n",
    "    \"\"\"Save all focused analysis results.\"\"\"\n",
    "    \n",
    "    # Combine all results\n",
    "    comprehensive_results = {\n",
    "        'dataset_info': report_summary['dataset_overview'],\n",
    "        'readability_analysis': readability_results[0],\n",
    "        'length_analysis': length_results[0],\n",
    "        'vocabulary_diversity': diversity_results[0],\n",
    "        'key_insights': report_summary['key_insights']\n",
    "    }\n",
    "    \n",
    "    # Save to JSON\n",
    "    with open('QA_Analysis.json', 'w') as f:\n",
    "        json.dump(comprehensive_results, f, indent=2, default=str)\n",
    "    print(f\" Complete analysis saved to: QA_Analysis.json\")\n",
    "    \n",
    "    # Save readability table to CSV\n",
    "    readability_results[1].to_csv('Readability_Analysis.csv', index=False)\n",
    "    print(f\" Readability analysis saved to: Readability_Analysis.csv\")\n",
    "    \n",
    "    # Save length analysis to CSV\n",
    "    length_results[1].to_csv('Length_Distribution_Analysis.csv', index=False)\n",
    "    print(f\" Length distribution analysis saved to: Length_Distribution_Analysis.csv\")\n",
    "    \n",
    "    # Save diversity analysis to CSV\n",
    "    diversity_results[1].to_csv('Vocabulary_Diversity_Analysis.csv', index=False)\n",
    "    print(f\" Vocabulary diversity analysis saved to: Vocabulary_Diversity_Analysis.csv\")\n",
    "    \n",
    "    print(f\"\\n  ANALYSIS COMPLETE!\")\n",
    "    print(f\" Files Generated:\")\n",
    "    print(f\" QA_Analysis_Complete.png - Complete 12-chart visualization\")\n",
    "    print(f\" QA_Analysis.json - Complete analysis results\")\n",
    "    print(f\" Readability_Analysis.csv - Flesch-Kincaid & Gunning Fog analysis\")\n",
    "    print(f\" Length_Distribution_Analysis.csv - Answer length statistics\")\n",
    "    print(f\" Vocabulary_Diversity_Analysis.csv - TTR and vocabulary size analysis\")\n",
    "\n",
    "#  Run Complete Analysis\n",
    "print(\" STARTING QA DATASET ANALYSIS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Run all analyses\n",
    "readability_results = analyze_readability(analyzer)\n",
    "length_results = analyze_answer_length_distribution(analyzer)\n",
    "diversity_results = analyze_vocabulary_diversity(analyzer)\n",
    "\n",
    "# Create comprehensive visualization\n",
    "create_comprehensive_visualization(analyzer, readability_results, length_results, diversity_results)\n",
    "\n",
    "# Generate statistical report\n",
    "report_summary = generate_statistical_report(analyzer, readability_results, length_results, diversity_results)\n",
    "\n",
    "# Save all results\n",
    "save_focused_results(analyzer, readability_results, length_results, diversity_results, report_summary)\n",
    "\n",
    "print(f\"\\n ANALYSIS COMPLETE! All requested analyses have been performed:\")\n",
    "print(f\"    Readability (Flesch-Kincaid & Gunning Fog) by shot types, question types, questions & answers\")\n",
    "print(f\"    Answer length distribution by shot types and question types\")\n",
    "print(f\"    Vocabulary diversity by shot types and question types\")\n",
    "print(f\"    One complete comprehensive visualization with all analyses\")\n",
    "print(f\"    Complete statistical report with key insights\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f141a3c1-c573-48d9-9059-8fbfc5b906a5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
